{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571800d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from skimage import color\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "import argparse\n",
    "import shutil\n",
    "import collections\n",
    "import numpy as np\n",
    "import scipy.misc as misc\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a219fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a95e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 128, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 128, 4, stride=1, padding=0, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.relu4 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(128, 1, 1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = self.conv1(h)\n",
    "        h = self.bn1(h)\n",
    "        h = self.relu1(h) # 64, 16, 16\n",
    "        \n",
    "        h = self.conv2(h)\n",
    "        h = self.bn2(h)\n",
    "        h = self.relu2(h) # 128, 8, 8\n",
    "        \n",
    "        h = self.conv3(h)\n",
    "        h = self.bn3(h)\n",
    "        h = self.relu3(h) # 128, 4, 4\n",
    "        \n",
    "        h = self.conv4(h)\n",
    "        h = self.bn4(h)\n",
    "        h = self.relu4(h) # 128, 1, 1\n",
    "        \n",
    "        h = self.conv5(h)\n",
    "        h = F.sigmoid(h)\n",
    "\n",
    "        return h\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a2c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 128, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.deconv4 = nn.ConvTranspose2d(128, 128, 3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.relu4 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.deconv5 = nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(64)\n",
    "        self.relu5 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.deconv6 = nn.ConvTranspose2d(64, 3, 3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.bn6 = nn.BatchNorm2d(3)\n",
    "        self.relu6 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = self.conv1(h)\n",
    "        h = self.bn1(h)\n",
    "        h = self.relu1(h) # 64, 16, 16\n",
    "        pool1 = h\n",
    "        \n",
    "        h = self.conv2(h)\n",
    "        h = self.bn2(h)\n",
    "        h = self.relu2(h) # 128, 8, 8\n",
    "        pool2 = h\n",
    "        \n",
    "        h = self.conv3(h)\n",
    "        h = self.bn3(h)\n",
    "        h = self.relu3(h) # 128, 4, 4\n",
    "        \n",
    "        h = self.deconv4(h)\n",
    "        h = self.bn4(h)\n",
    "        h = self.relu4(h) # 128, 8, 8\n",
    "        h += pool2\n",
    "        \n",
    "        h = self.deconv5(h)\n",
    "        h = self.bn5(h)\n",
    "        h = self.relu5(h) # 64, 16, 16\n",
    "        h += pool1\n",
    "        \n",
    "        h = self.deconv6(h)\n",
    "        h = F.tanh(h) # 3, 32, 32\n",
    "\n",
    "        return h\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f1727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35260822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e757c407d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3467b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f52513ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "   'path': '',\n",
    "   'dataset': '',\n",
    "   'large': False,\n",
    "   'batch_size': 32,\n",
    "   'lr': 1e-4,\n",
    "   'weight_decay': 0,\n",
    "   'num_epoch': 15,\n",
    "   'lamb': 100,\n",
    "   'test': '',\n",
    "   'generator': 'model/1126.filter1/GAN__100L1_bs32_Adam_lr0.0001/G_epoch14.pth.tar',\n",
    "   'discriminator': 'model/1126.filter1/GAN__100L1_bs32_Adam_lr0.0001/D_epoch14.pth.tar',\n",
    "   'save': True,\n",
    "   'gpu': 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "139fe0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset\n",
    "\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, X_train, y_train):\n",
    "#         self.X_train = X_train\n",
    "#         self.y_train = y_train\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.X_train)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img = self.X_train[idx]\n",
    "#         img = np.array(img)\n",
    "\n",
    "#         img_lab = self.y_train[idx]\n",
    "#         img_lab = np.array(img_lab)\n",
    "\n",
    "#         img = torch.FloatTensor(np.transpose(img, (2,0,1)))\n",
    "#         img_lab = torch.FloatTensor(np.transpose(img_lab, (2,0,1)))\n",
    "\n",
    "#         img = np.reshape(img, img.shape+(1,))\n",
    "#         img_lab = np.reshape(img_lab, img_lab.shape+(1,))\n",
    "\n",
    "\n",
    "#         return img, img_lab\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5de81cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dataset_train = 'dataset/train'\n",
    "root_dataset_test = 'dataset/test'\n",
    "X_train_images_dir = f'dataset/train/filter{1}'\n",
    "X_test_dir = f'dataset/test/filter{1}_test'\n",
    "y_train_images_dir = f'dataset/train/y_train'\n",
    "y_test_dir = f'dataset/test/y_test'\n",
    "X_train, X_test = [], []\n",
    "y_train, y_test = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(32), transforms.CenterCrop(32), transforms.ToTensor()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "   def __init__(self, X_dir, y_dir, transform=None):\n",
    "       self.X_dir = X_dir\n",
    "       self.y_dir = y_dir\n",
    "       self.transform = transform\n",
    "       self.X_filenames = os.listdir(X_dir)\n",
    "       self.y_filenames = os.listdir(y_dir)\n",
    "\n",
    "   def __len__(self):\n",
    "       return len(self.X_filenames)\n",
    "\n",
    "   def __getitem__(self, idx):\n",
    "       X_path = os.path.join(self.X_dir, self.X_filenames[idx])\n",
    "       y_path = os.path.join(self.y_dir, self.y_filenames[idx])\n",
    "       X = Image.open(X_path).convert('L')\n",
    "       y = Image.open(y_path)\n",
    "       if self.transform:\n",
    "           X = self.transform(X)\n",
    "           y = self.transform(y)\n",
    "       return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CustomDataset(X_train_images_dir, y_train_images_dir, transform=transform)\n",
    "\n",
    "train_loader = data.DataLoader(dataset_train, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = CustomDataset(X_test_dir, y_test_dir, transform=transform)\n",
    "\n",
    "val_loader = data.DataLoader(dataset_test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "761a32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in os.listdir(X_train_images_dir):\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         img = cv2.imread(os.path.join(X_train_images_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "#         X_train.append(img)\n",
    "# for filename in os.listdir(X_test_dir):\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         img = cv2.imread(os.path.join(X_test_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "#         X_test.append(img)\n",
    "# for filename in os.listdir(y_train_images_dir):\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         img = cv2.imread(os.path.join(y_train_images_dir, filename))\n",
    "#         y_train.append(img)\n",
    "# for filename in os.listdir(y_test_dir):\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         img = cv2.imread(os.path.join(y_test_dir, filename))\n",
    "#         y_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9be6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #X_train_tensor = torch.from_numpy(np.array(X_train))\n",
    "# #y_train_tensor = torch.from_numpy(np.array(y_train))\n",
    "\n",
    "# X_train = [x.astype('float32') for x in X_train]\n",
    "# y_train = [y.astype('float32') for y in y_train]\n",
    "\n",
    "\n",
    "# dataset = CustomDataset(X_train, y_train)\n",
    "# dataset_val = CustomDataset(X_test, y_test)\n",
    "# #train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "# batch_size = 32\n",
    "# train_loader = data.DataLoader(\n",
    "#     dataset, batch_size=args_dict['batch_size'], shuffle=False\n",
    "# )\n",
    "\n",
    "# batch_size = 32\n",
    "# val_loader = data.DataLoader(\n",
    "#     dataset_val, batch_size=args_dict['batch_size'], shuffle=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee136e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.array(X_train).shape)\n",
    "# print(np.array(y_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c2fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57636131",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device=device)\n",
    "discriminator = Discriminator().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502bee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "467f836d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume model G: model/1126.filter1/GAN__100L1_bs32_Adam_lr0.0001/G_epoch14.pth.tar\n",
      "Resume model D: model/1126.filter1/GAN__100L1_bs32_Adam_lr0.0001/D_epoch14.pth.tar\n"
     ]
    }
   ],
   "source": [
    "start_epoch_G = start_epoch_D = 0\n",
    "if args_dict['generator']:\n",
    "    print('Resume model G: %s' % args_dict['generator'])\n",
    "    checkpoint_G = torch.load(args_dict['generator'])\n",
    "    generator.load_state_dict(checkpoint_G['state_dict'])\n",
    "    start_epoch_G = checkpoint_G['epoch']\n",
    "if args_dict['discriminator']:\n",
    "    print('Resume model D: %s' % args_dict['discriminator'])\n",
    "    checkpoint_D = torch.load(args_dict['discriminator'])\n",
    "    discriminator.load_state_dict(checkpoint_D['state_dict'])\n",
    "    start_epoch_D = checkpoint_D['epoch']\n",
    "assert start_epoch_G == start_epoch_D\n",
    "if args_dict['generator'] == '' and args_dict['discriminator'] == '':\n",
    "    print('No Resume')\n",
    "    start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c33284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e7d081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "num_epochs = 50\n",
    "criterion = nn.BCELoss()\n",
    "L1 = nn.L1Loss()\n",
    "\n",
    "optimizer_discriminator = optim.Adam(discriminator.parameters(), \n",
    "            lr=args_dict['lr'], betas=(0.5, 0.999), \n",
    "            eps=1e-8, weight_decay=args_dict['weight_decay'])\n",
    "optimizer_generator = optim.Adam(generator.parameters(), \n",
    "            lr=args_dict['lr'], betas=(0.5, 0.999),\n",
    "            eps=1e-8, weight_decay=args_dict['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12950d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args_dict['generator']:\n",
    "    optimizer_generator.load_state_dict(checkpoint_G['optimizer'])\n",
    "if args_dict['discriminator']:\n",
    "    optimizer_discriminator.load_state_dict(checkpoint_D['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fe101a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scale(object):\n",
    "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "        assert isinstance(size, int) or (isinstance(size, collections.Iterable) and len(size) == 2)\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, img):\n",
    "        print(\"scale\")\n",
    "        if isinstance(self.size, int):\n",
    "            w, h = img.size\n",
    "            if (w <= h and w == self.size) or (h <= w and h == self.size):\n",
    "                return img\n",
    "            if w < h:\n",
    "                ow = self.size\n",
    "                oh = int(self.size * h / w)\n",
    "                return img.resize((ow, oh), self.interpolation)\n",
    "            else:\n",
    "                oh = self.size\n",
    "                ow = int(self.size * w / h)\n",
    "                return img.resize((ow, oh), self.interpolation)\n",
    "        else:\n",
    "            # import ipdb; ipdb.set_trace()\n",
    "            return img.resize(self.size, self.interpolation)\n",
    "        \n",
    "        \n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.history = []\n",
    "        self.dict = {} # save all data values here\n",
    "        self.save_dict = {} # save mean and std here, for summary table\n",
    "\n",
    "    def update(self, val, n=1, history=0):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        if history:\n",
    "            self.history.append(val)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.count\n",
    "\n",
    "class Plotter_GAN(object):\n",
    "    \"\"\"plot loss for G and D\"\"\"\n",
    "    def __init__(self):\n",
    "        self.g_loss = []\n",
    "        self.d_loss = []\n",
    "\n",
    "    def g_update(self, loss):\n",
    "        if type(loss) != float:\n",
    "            loss = float(loss)\n",
    "        self.g_loss.append(loss)\n",
    "\n",
    "    def d_update(self, loss):\n",
    "        if type(loss) != float:\n",
    "            loss = float(loss)\n",
    "        self.d_loss.append(loss)\n",
    "\n",
    "    def draw(self, filename):\n",
    "        name = 'loss'\n",
    "        if len(self.g_loss) == len(self.d_loss):\n",
    "            plt.figure()\n",
    "            plt.plot(self.g_loss, label='G')\n",
    "            plt.plot(self.d_loss, label='D')\n",
    "            plt.legend(loc='upper left')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.title(name)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(filename)\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "\n",
    "class Plotter_GAN_TV(object):\n",
    "    \"\"\"plot loss for G and D with Training and Validation\"\"\"\n",
    "    def __init__(self):\n",
    "        self.g_loss_t = []\n",
    "        self.d_loss_t = []\n",
    "        self.g_loss_v = []\n",
    "        self.d_loss_v = []\n",
    "\n",
    "    def train_update(self, g_loss, d_loss):\n",
    "        if type(g_loss) != float:\n",
    "            g_loss = float(g_loss)\n",
    "        if type(d_loss) != float:\n",
    "            d_loss = float(d_loss)\n",
    "        self.g_loss_t.append(g_loss)\n",
    "        self.d_loss_t.append(d_loss)\n",
    "\n",
    "    def val_update(self, g_loss, d_loss):\n",
    "        if type(g_loss) != float:\n",
    "            g_loss = float(g_loss)\n",
    "        if type(d_loss) != float:\n",
    "            d_loss = float(d_loss)\n",
    "        self.g_loss_v.append(g_loss)\n",
    "        self.d_loss_v.append(d_loss)\n",
    "\n",
    "    def draw(self, filename):\n",
    "        name = 'loss'\n",
    "        if len(self.g_loss_t) == len(self.d_loss_t) and\\\n",
    "           len(self.g_loss_v) == len(self.d_loss_v) and\\\n",
    "           len(self.g_loss_t) == len(self.g_loss_v):\n",
    "            plt.figure()\n",
    "            plt.plot(self.g_loss_t, label='G_train')\n",
    "            plt.plot(self.d_loss_t, label='D_train')\n",
    "            plt.plot(self.g_loss_v, label='G_val')\n",
    "            plt.plot(self.d_loss_v, label='D_val')\n",
    "            plt.legend(loc='upper left')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.title(name)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(filename)\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f69acd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 0\n",
    "print_interval = 500\n",
    "plotter = Plotter_GAN_TV()\n",
    "plotter_basic = Plotter_GAN()\n",
    "date = f'1126.test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "606ef684",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = ''\n",
    "img_path = 'img/%s/GAN_%s%s_%dL1_bs%d_%s_lr%s/' \\\n",
    "           % (date, args_dict['dataset'], size, args_dict['lamb'], args_dict['batch_size'], 'Adam', str(args_dict['lr']))\n",
    "model_path = 'model/%s/GAN_%s%s_%dL1_bs%d_%s_lr%s/' \\\n",
    "           % (date, args_dict['dataset'], size, args_dict['lamb'], args_dict['batch_size'], 'Adam', str(args_dict['lr']))\n",
    "if not os.path.exists(img_path):\n",
    "    os.makedirs(img_path)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best=0, filename='models/checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'models/model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "328e94c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model_G, model_D, optimizer_G, optimizer_D, epoch, iteration):\n",
    "    errorG = AverageMeter() # will be reset after each epoch\n",
    "    errorD = AverageMeter() # will be reset after each epoch\n",
    "    errorG_basic = AverageMeter() # basic will be reset after each print\n",
    "    errorD_basic = AverageMeter() # basic will be reset after each print\n",
    "    errorD_real = AverageMeter()\n",
    "    errorD_fake = AverageMeter()\n",
    "    errorG_GAN = AverageMeter()\n",
    "    errorG_R = AverageMeter()\n",
    "\n",
    "    model_G.train()\n",
    "    model_D.train()\n",
    "\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data.to(device=device)), Variable(target.to(device=device))\n",
    "\n",
    "        ########################\n",
    "        # update D network\n",
    "        ########################\n",
    "        # train with real\n",
    "        model_D.zero_grad()\n",
    "        output = model_D(target)\n",
    "        label = torch.FloatTensor(target.size(0)).fill_(real_label).to(device=device)\n",
    "        labelv = Variable(label)\n",
    "        errD_real = criterion(torch.squeeze(output), labelv)\n",
    "        errD_real.backward()\n",
    "        D_x = output.data.mean()\n",
    "\n",
    "        # train with fake\n",
    "        fake =  model_G(data)\n",
    "        labelv = Variable(label.fill_(fake_label))\n",
    "        output = model_D(fake.detach())\n",
    "        errD_fake = criterion(torch.squeeze(output), labelv)\n",
    "        errD_fake.backward()\n",
    "        D_G_x1 = output.data.mean()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizer_D.step()\n",
    "\n",
    "        ########################\n",
    "        # update G network\n",
    "        ########################\n",
    "        model_G.zero_grad()\n",
    "        labelv = Variable(label.fill_(real_label))\n",
    "        output = model_D(fake)\n",
    "        errG_GAN = criterion(torch.squeeze(output), labelv)\n",
    "        errG_L1 = L1(fake.view(fake.size(0),-1), target.view(target.size(0),-1))\n",
    "\n",
    "        errG = errG_GAN + args_dict['lamb'] * errG_L1\n",
    "        errG.backward()\n",
    "        D_G_x2 = output.data.mean()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # store error values\n",
    "        errorG.update(errG.item(), target.size(0), history=1)\n",
    "        errorD.update(errD.item(), target.size(0), history=1)\n",
    "        errorG_basic.update(errG.item(), target.size(0), history=1)\n",
    "        errorD_basic.update(errD.item(), target.size(0), history=1)\n",
    "        errorD_real.update(errD_real.item(), target.size(0), history=1)\n",
    "        errorD_fake.update(errD_fake.item(), target.size(0), history=1)\n",
    "\n",
    "        errorD_real.update(errD_real.item(), target.size(0), history=1)\n",
    "        errorD_fake.update(errD_fake.item(), target.size(0), history=1)\n",
    "        errorG_GAN.update(errG_GAN.item(), target.size(0), history=1)\n",
    "        errorG_R.update(errG_L1.item(), target.size(0), history=1)\n",
    "\n",
    "        if iteration % print_interval == 0:\n",
    "            print('Epoch%d[%d/%d]: Loss_D: %.4f (R %0.4f + F %0.4f) Loss_G: %0.4f (GAN %.4f + R %0.4f) D(x): %.4f D(G(z)): %.4f / %.4f' \\\n",
    "                % (epoch, i, len(train_loader),\n",
    "                errorD_basic.avg, errorD_real.avg, errorD_fake.avg,\n",
    "                errorG_basic.avg, errorG_GAN.avg, errorG_R.avg,\n",
    "                D_x, D_G_x1, D_G_x2\n",
    "                ))\n",
    "            # plot image\n",
    "            plotter_basic.g_update(errorG_basic.avg)\n",
    "            plotter_basic.d_update(errorD_basic.avg)\n",
    "            plotter_basic.draw(img_path + 'train_basic.png')\n",
    "            # reset AverageMeter\n",
    "            errorG_basic.reset()\n",
    "            errorD_basic.reset()\n",
    "            errorD_real.reset()\n",
    "            errorD_fake.reset()\n",
    "            errorG_GAN.reset()\n",
    "            errorG_R.reset()\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    return errorG.avg, errorD.avg\n",
    "\n",
    "\n",
    "def validate(val_loader, model_G, model_D, optimizer_G, optimizer_D, epoch):\n",
    "    errorG = AverageMeter()\n",
    "    errorD = AverageMeter()\n",
    "\n",
    "    model_G.eval()\n",
    "    model_D.eval()\n",
    "\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "\n",
    "    i = 0\n",
    "    for i, (data, target) in enumerate(val_loader):\n",
    "        data, target = Variable(data.to(device=device)), Variable(target.to(device=device))\n",
    "        ########################\n",
    "        # D network\n",
    "        ########################\n",
    "        # validate with real\n",
    "        output = model_D(target)\n",
    "        label = torch.FloatTensor(target.size(0)).fill_(real_label).to(device=device)\n",
    "        labelv = Variable(label)\n",
    "        errD_real = criterion(torch.squeeze(output), labelv)\n",
    "\n",
    "        # validate with fake\n",
    "        fake =  model_G(data)\n",
    "        labelv = Variable(label.fill_(fake_label))\n",
    "        output = model_D(fake.detach())\n",
    "        errD_fake = criterion(torch.squeeze(output), labelv)\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "\n",
    "        ########################\n",
    "        # G network\n",
    "        ########################\n",
    "        labelv = Variable(label.fill_(real_label))\n",
    "        output = model_D(fake)\n",
    "        errG_GAN = criterion(torch.squeeze(output), labelv)\n",
    "        errG_L1 = L1(fake.view(fake.size(0),-1), target.view(target.size(0),-1))\n",
    "\n",
    "        errG = errG_GAN + args_dict['lamb'] * errG_L1\n",
    "\n",
    "        errorG.update(errG.item(), target.size(0), history=1)\n",
    "        errorD.update(errD.item(), target.size(0), history=1)\n",
    "\n",
    "        if i == 0:\n",
    "            vis_result(data.data, target.data, fake.data, epoch)\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('Validating Epoch %d: [%d/%d]' \\\n",
    "                % (epoch, i, len(val_loader)))\n",
    "        \n",
    "\n",
    "    print('Validation: Loss_D: %.4f Loss_G: %.4f '\\\n",
    "        % (errorD.avg, errorG.avg))\n",
    "\n",
    "    return errorG.avg, errorD.avg\n",
    "\n",
    "def vis_result(data, target, output, epoch):\n",
    "    '''visualize images for GAN'''\n",
    "    img_list = []\n",
    "    for i in range(32):\n",
    "        l = torch.unsqueeze(torch.squeeze(data[i]), 0).cpu().numpy()\n",
    "        raw = target[i].cpu().numpy()\n",
    "        pred = output[i].cpu().numpy()\n",
    "\n",
    "        raw_rgb = (np.transpose(raw, (1,2,0)).astype(np.float64) + 1) / 2.\n",
    "        pred_rgb = (np.transpose(pred, (1,2,0)).astype(np.float64) + 1) / 2.\n",
    "\n",
    "        grey = np.transpose(l, (1,2,0))\n",
    "        grey = np.repeat(grey, 3, axis=2).astype(np.float64)\n",
    "        img_list.append(np.concatenate((grey, raw_rgb, pred_rgb), 1))\n",
    "\n",
    "    img_list = [np.concatenate(img_list[4*i:4*(i+1)], axis=1) for i in range(len(img_list) // 4)]\n",
    "    img_list = np.concatenate(img_list, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(36,27))\n",
    "    plt.imshow(img_list)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(img_path + 'epoch%d_val.png' % epoch)\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1149dcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a3941e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "--------------------\n",
      "Validating Epoch -1: [0/313]\n",
      "Validating Epoch -1: [50/313]\n",
      "Validating Epoch -1: [100/313]\n",
      "Validating Epoch -1: [150/313]\n",
      "Validating Epoch -1: [200/313]\n",
      "Validating Epoch -1: [250/313]\n",
      "Validating Epoch -1: [300/313]\n",
      "Validation: Loss_D: 1.7515 Loss_G: 46.8201 \n",
      "Epoch0[0/1563]: Loss_D: 13.7838 (R 9.0547 + F 4.7291) Loss_G: 92.7414 (GAN 8.5013 + R 0.8424) D(x): 0.3203 D(G(z)): 0.2268 / 0.1728\n",
      "Epoch0[500/1563]: Loss_D: 4.9450 (R 3.3237 + F 1.6213) Loss_G: 63.8727 (GAN 4.7411 + R 0.5913) D(x): 0.3945 D(G(z)): 0.3662 / 0.3020\n",
      "Epoch0[1000/1563]: Loss_D: 1.4646 (R 0.6376 + F 0.8270) Loss_G: 45.5727 (GAN 2.7802 + R 0.4279) D(x): 0.9251 D(G(z)): 0.2021 / 0.1711\n",
      "Epoch0[1500/1563]: Loss_D: 0.8391 (R 0.3938 + F 0.4453) Loss_G: 37.8155 (GAN 2.6903 + R 0.3513) D(x): 0.7481 D(G(z)): 0.1721 / 0.1366\n",
      "Validating Epoch 0: [0/313]\n",
      "Validating Epoch 0: [50/313]\n",
      "Validating Epoch 0: [100/313]\n",
      "Validating Epoch 0: [150/313]\n",
      "Validating Epoch 0: [200/313]\n",
      "Validating Epoch 0: [250/313]\n",
      "Validating Epoch 0: [300/313]\n",
      "Validation: Loss_D: 4.0212 Loss_G: 31.9306 \n",
      "Saving check point\n",
      "Epoch 1/14\n",
      "--------------------\n",
      "Epoch1[0/1563]: Loss_D: 0.4309 (R 0.1936 + F 0.2373) Loss_G: 34.6723 (GAN 3.1022 + R 0.3157) D(x): 0.8565 D(G(z)): 0.1449 / 0.1232\n",
      "Epoch1[500/1563]: Loss_D: 0.5988 (R 0.2886 + F 0.3102) Loss_G: 31.2102 (GAN 2.7833 + R 0.2843) D(x): 0.9548 D(G(z)): 0.1949 / 0.1603\n",
      "Epoch1[1000/1563]: Loss_D: 0.4626 (R 0.2341 + F 0.2284) Loss_G: 27.8103 (GAN 2.9316 + R 0.2488) D(x): 0.9334 D(G(z)): 0.1454 / 0.1114\n",
      "Epoch1[1500/1563]: Loss_D: 0.3488 (R 0.1772 + F 0.1716) Loss_G: 26.1434 (GAN 3.1299 + R 0.2301) D(x): 0.9028 D(G(z)): 0.0732 / 0.0645\n",
      "Validating Epoch 1: [0/313]\n",
      "Validating Epoch 1: [50/313]\n",
      "Validating Epoch 1: [100/313]\n",
      "Validating Epoch 1: [150/313]\n",
      "Validating Epoch 1: [200/313]\n",
      "Validating Epoch 1: [250/313]\n",
      "Validating Epoch 1: [300/313]\n",
      "Validation: Loss_D: 2.2052 Loss_G: 23.2479 \n",
      "Saving check point\n",
      "Epoch 2/14\n",
      "--------------------\n",
      "Epoch2[0/1563]: Loss_D: 0.2376 (R 0.0619 + F 0.1757) Loss_G: 25.7674 (GAN 3.4017 + R 0.2237) D(x): 0.9460 D(G(z)): 0.1058 / 0.0778\n",
      "Epoch2[500/1563]: Loss_D: 0.2514 (R 0.1289 + F 0.1225) Loss_G: 25.4238 (GAN 3.4133 + R 0.2201) D(x): 0.9593 D(G(z)): 0.0995 / 0.0843\n",
      "Epoch2[1000/1563]: Loss_D: 0.2941 (R 0.1556 + F 0.1386) Loss_G: 25.0808 (GAN 3.3116 + R 0.2177) D(x): 0.9869 D(G(z)): 0.0861 / 0.0667\n",
      "Epoch2[1500/1563]: Loss_D: 0.1801 (R 0.0944 + F 0.0857) Loss_G: 24.6802 (GAN 3.6441 + R 0.2104) D(x): 0.9340 D(G(z)): 0.0506 / 0.0393\n",
      "Validating Epoch 2: [0/313]\n",
      "Validating Epoch 2: [50/313]\n",
      "Validating Epoch 2: [100/313]\n",
      "Validating Epoch 2: [150/313]\n",
      "Validating Epoch 2: [200/313]\n",
      "Validating Epoch 2: [250/313]\n",
      "Validating Epoch 2: [300/313]\n",
      "Validation: Loss_D: 3.2509 Loss_G: 22.8441 \n",
      "Saving check point\n",
      "Epoch 3/14\n",
      "--------------------\n",
      "Epoch3[0/1563]: Loss_D: 0.9770 (R 0.6571 + F 0.3199) Loss_G: 24.1408 (GAN 2.2449 + R 0.2190) D(x): 0.7608 D(G(z)): 0.2307 / 0.2176\n",
      "Epoch3[500/1563]: Loss_D: 0.2519 (R 0.1343 + F 0.1176) Loss_G: 24.9454 (GAN 3.5090 + R 0.2144) D(x): 0.9843 D(G(z)): 0.0599 / 0.0476\n",
      "Epoch3[1000/1563]: Loss_D: 0.1367 (R 0.0622 + F 0.0745) Loss_G: 25.0017 (GAN 4.0746 + R 0.2093) D(x): 0.9544 D(G(z)): 0.0535 / 0.0387\n",
      "Epoch3[1500/1563]: Loss_D: 0.0990 (R 0.0537 + F 0.0454) Loss_G: 24.7873 (GAN 4.1477 + R 0.2064) D(x): 0.9842 D(G(z)): 0.0144 / 0.0138\n",
      "Validating Epoch 3: [0/313]\n",
      "Validating Epoch 3: [50/313]\n",
      "Validating Epoch 3: [100/313]\n",
      "Validating Epoch 3: [150/313]\n",
      "Validating Epoch 3: [200/313]\n",
      "Validating Epoch 3: [250/313]\n",
      "Validating Epoch 3: [300/313]\n",
      "Validation: Loss_D: 2.8511 Loss_G: 20.5123 \n",
      "Saving check point\n",
      "Epoch 4/14\n",
      "--------------------\n",
      "Epoch4[0/1563]: Loss_D: 0.0514 (R 0.0093 + F 0.0421) Loss_G: 24.9207 (GAN 4.4670 + R 0.2045) D(x): 0.9909 D(G(z)): 0.0338 / 0.0191\n",
      "Epoch4[500/1563]: Loss_D: 0.2096 (R 0.1158 + F 0.0937) Loss_G: 25.4681 (GAN 3.9329 + R 0.2154) D(x): 0.9790 D(G(z)): 0.0523 / 0.0395\n",
      "Epoch4[1000/1563]: Loss_D: 0.1184 (R 0.0540 + F 0.0643) Loss_G: 25.1846 (GAN 3.9041 + R 0.2128) D(x): 0.9786 D(G(z)): 0.0651 / 0.0442\n",
      "Epoch4[1500/1563]: Loss_D: 0.0870 (R 0.0472 + F 0.0398) Loss_G: 25.0820 (GAN 4.3612 + R 0.2072) D(x): 0.9871 D(G(z)): 0.0318 / 0.0302\n",
      "Validating Epoch 4: [0/313]\n",
      "Validating Epoch 4: [50/313]\n",
      "Validating Epoch 4: [100/313]\n",
      "Validating Epoch 4: [150/313]\n",
      "Validating Epoch 4: [200/313]\n",
      "Validating Epoch 4: [250/313]\n",
      "Validating Epoch 4: [300/313]\n",
      "Validation: Loss_D: 1.6559 Loss_G: 20.4887 \n",
      "Saving check point\n",
      "Epoch 5/14\n",
      "--------------------\n",
      "Epoch5[0/1563]: Loss_D: 0.0346 (R 0.0015 + F 0.0331) Loss_G: 23.0967 (GAN 3.8797 + R 0.1922) D(x): 0.9985 D(G(z)): 0.0324 / 0.0309\n",
      "Epoch5[500/1563]: Loss_D: 0.0411 (R 0.0218 + F 0.0194) Loss_G: 24.7381 (GAN 4.5750 + R 0.2016) D(x): 0.9933 D(G(z)): 0.0084 / 0.0083\n",
      "Epoch5[1000/1563]: Loss_D: 0.0553 (R 0.0247 + F 0.0306) Loss_G: 25.4695 (GAN 4.6724 + R 0.2080) D(x): 0.9835 D(G(z)): 0.0413 / 0.0253\n",
      "Epoch5[1500/1563]: Loss_D: 0.0857 (R 0.0442 + F 0.0415) Loss_G: 26.0292 (GAN 4.9552 + R 0.2107) D(x): 0.9802 D(G(z)): 0.0155 / 0.0139\n",
      "Validating Epoch 5: [0/313]\n",
      "Validating Epoch 5: [50/313]\n",
      "Validating Epoch 5: [100/313]\n",
      "Validating Epoch 5: [150/313]\n",
      "Validating Epoch 5: [200/313]\n",
      "Validating Epoch 5: [250/313]\n",
      "Validating Epoch 5: [300/313]\n",
      "Validation: Loss_D: 1.1782 Loss_G: 21.0873 \n",
      "Saving check point\n",
      "Epoch 6/14\n",
      "--------------------\n",
      "Epoch6[0/1563]: Loss_D: 0.0182 (R 0.0006 + F 0.0176) Loss_G: 26.0807 (GAN 4.3861 + R 0.2169) D(x): 0.9994 D(G(z)): 0.0174 / 0.0168\n",
      "Epoch6[500/1563]: Loss_D: 0.0382 (R 0.0224 + F 0.0158) Loss_G: 24.8701 (GAN 4.7855 + R 0.2008) D(x): 0.9975 D(G(z)): 0.0091 / 0.0086\n",
      "Epoch6[1000/1563]: Loss_D: 0.0977 (R 0.0559 + F 0.0418) Loss_G: 25.3940 (GAN 4.8189 + R 0.2058) D(x): 0.9872 D(G(z)): 0.0568 / 0.0229\n",
      "Epoch6[1500/1563]: Loss_D: 0.3765 (R 0.1985 + F 0.1780) Loss_G: 26.4237 (GAN 4.0115 + R 0.2241) D(x): 0.9734 D(G(z)): 0.1838 / 0.1099\n",
      "Validating Epoch 6: [0/313]\n",
      "Validating Epoch 6: [50/313]\n",
      "Validating Epoch 6: [100/313]\n",
      "Validating Epoch 6: [150/313]\n",
      "Validating Epoch 6: [200/313]\n",
      "Validating Epoch 6: [250/313]\n",
      "Validating Epoch 6: [300/313]\n",
      "Validation: Loss_D: 2.2161 Loss_G: 23.4524 \n",
      "Saving check point\n",
      "Epoch 7/14\n",
      "--------------------\n",
      "Epoch7[0/1563]: Loss_D: 0.0395 (R 0.0070 + F 0.0324) Loss_G: 26.0881 (GAN 5.1367 + R 0.2095) D(x): 0.9931 D(G(z)): 0.0261 / 0.0158\n",
      "Epoch7[500/1563]: Loss_D: 0.0343 (R 0.0164 + F 0.0179) Loss_G: 24.7674 (GAN 4.6379 + R 0.2013) D(x): 0.9983 D(G(z)): 0.0127 / 0.0122\n",
      "Epoch7[1000/1563]: Loss_D: 0.0681 (R 0.0276 + F 0.0405) Loss_G: 25.1351 (GAN 4.3881 + R 0.2075) D(x): 0.9695 D(G(z)): 0.0259 / 0.0155\n",
      "Epoch7[1500/1563]: Loss_D: 0.0419 (R 0.0146 + F 0.0273) Loss_G: 26.0739 (GAN 5.2118 + R 0.2086) D(x): 0.9854 D(G(z)): 0.0036 / 0.0036\n",
      "Validating Epoch 7: [0/313]\n",
      "Validating Epoch 7: [50/313]\n",
      "Validating Epoch 7: [100/313]\n",
      "Validating Epoch 7: [150/313]\n",
      "Validating Epoch 7: [200/313]\n",
      "Validating Epoch 7: [250/313]\n",
      "Validating Epoch 7: [300/313]\n",
      "Validation: Loss_D: 0.9663 Loss_G: 21.1814 \n",
      "Saving check point\n",
      "Epoch 8/14\n",
      "--------------------\n",
      "Epoch8[0/1563]: Loss_D: 0.0394 (R 0.0234 + F 0.0160) Loss_G: 26.5501 (GAN 5.0830 + R 0.2147) D(x): 0.9776 D(G(z)): 0.0158 / 0.0146\n",
      "Epoch8[500/1563]: Loss_D: 0.0291 (R 0.0188 + F 0.0103) Loss_G: 25.6460 (GAN 5.1762 + R 0.2047) D(x): 0.9993 D(G(z)): 0.0173 / 0.0114\n",
      "Epoch8[1000/1563]: Loss_D: 0.0313 (R 0.0125 + F 0.0188) Loss_G: 26.0208 (GAN 5.1807 + R 0.2084) D(x): 0.9892 D(G(z)): 0.0239 / 0.0190\n",
      "Epoch8[1500/1563]: Loss_D: 0.0330 (R 0.0177 + F 0.0152) Loss_G: 26.3858 (GAN 5.7278 + R 0.2066) D(x): 0.9814 D(G(z)): 0.0054 / 0.0056\n",
      "Validating Epoch 8: [0/313]\n",
      "Validating Epoch 8: [50/313]\n",
      "Validating Epoch 8: [100/313]\n",
      "Validating Epoch 8: [150/313]\n",
      "Validating Epoch 8: [200/313]\n",
      "Validating Epoch 8: [250/313]\n",
      "Validating Epoch 8: [300/313]\n",
      "Validation: Loss_D: 0.9073 Loss_G: 21.0552 \n",
      "Saving check point\n",
      "Epoch 9/14\n",
      "--------------------\n",
      "Epoch9[0/1563]: Loss_D: 0.0089 (R 0.0013 + F 0.0076) Loss_G: 25.2367 (GAN 5.5363 + R 0.1970) D(x): 0.9987 D(G(z)): 0.0075 / 0.0073\n",
      "Epoch9[500/1563]: Loss_D: 0.0137 (R 0.0056 + F 0.0081) Loss_G: 26.2210 (GAN 5.7516 + R 0.2047) D(x): 0.9955 D(G(z)): 0.0047 / 0.0043\n",
      "Epoch9[1000/1563]: Loss_D: 0.0303 (R 0.0139 + F 0.0164) Loss_G: 26.0450 (GAN 5.8716 + R 0.2017) D(x): 0.9993 D(G(z)): 0.0034 / 0.0034\n",
      "Epoch9[1500/1563]: Loss_D: 0.0165 (R 0.0081 + F 0.0083) Loss_G: 26.1542 (GAN 6.0909 + R 0.2006) D(x): 0.9999 D(G(z)): 0.0018 / 0.0018\n",
      "Validating Epoch 9: [0/313]\n",
      "Validating Epoch 9: [50/313]\n",
      "Validating Epoch 9: [100/313]\n",
      "Validating Epoch 9: [150/313]\n",
      "Validating Epoch 9: [200/313]\n",
      "Validating Epoch 9: [250/313]\n",
      "Validating Epoch 9: [300/313]\n",
      "Validation: Loss_D: 2.2078 Loss_G: 23.4560 \n",
      "Saving check point\n",
      "Epoch 10/14\n",
      "--------------------\n",
      "Epoch10[0/1563]: Loss_D: 0.0056 (R 0.0020 + F 0.0036) Loss_G: 26.6262 (GAN 6.0836 + R 0.2054) D(x): 0.9980 D(G(z)): 0.0035 / 0.0036\n",
      "Epoch10[500/1563]: Loss_D: 0.0273 (R 0.0104 + F 0.0168) Loss_G: 26.4421 (GAN 5.3147 + R 0.2113) D(x): 0.9970 D(G(z)): 0.0070 / 0.0067\n",
      "Epoch10[1000/1563]: Loss_D: 0.0180 (R 0.0102 + F 0.0078) Loss_G: 27.0607 (GAN 6.4176 + R 0.2064) D(x): 0.9773 D(G(z)): 0.0033 / 0.0036\n",
      "Epoch10[1500/1563]: Loss_D: 0.1579 (R 0.0906 + F 0.0673) Loss_G: 27.9944 (GAN 5.4712 + R 0.2252) D(x): 0.8085 D(G(z)): 0.0042 / 0.0079\n",
      "Validating Epoch 10: [0/313]\n",
      "Validating Epoch 10: [50/313]\n",
      "Validating Epoch 10: [100/313]\n",
      "Validating Epoch 10: [150/313]\n",
      "Validating Epoch 10: [200/313]\n",
      "Validating Epoch 10: [250/313]\n",
      "Validating Epoch 10: [300/313]\n",
      "Validation: Loss_D: 1.6375 Loss_G: 24.4601 \n",
      "Saving check point\n",
      "Epoch 11/14\n",
      "--------------------\n",
      "Epoch11[0/1563]: Loss_D: 0.0655 (R 0.0137 + F 0.0518) Loss_G: 28.0136 (GAN 4.3236 + R 0.2369) D(x): 0.9868 D(G(z)): 0.0481 / 0.0283\n",
      "Epoch11[500/1563]: Loss_D: 0.2837 (R 0.1598 + F 0.1239) Loss_G: 28.0770 (GAN 4.4026 + R 0.2367) D(x): 0.9978 D(G(z)): 0.0039 / 0.0039\n",
      "Epoch11[1000/1563]: Loss_D: 0.0365 (R 0.0106 + F 0.0259) Loss_G: 26.1275 (GAN 5.5151 + R 0.2061) D(x): 0.9827 D(G(z)): 0.0168 / 0.0141\n",
      "Epoch11[1500/1563]: Loss_D: 0.0299 (R 0.0124 + F 0.0175) Loss_G: 26.0122 (GAN 5.1211 + R 0.2089) D(x): 0.9904 D(G(z)): 0.0105 / 0.0101\n",
      "Validating Epoch 11: [0/313]\n",
      "Validating Epoch 11: [50/313]\n",
      "Validating Epoch 11: [100/313]\n",
      "Validating Epoch 11: [150/313]\n",
      "Validating Epoch 11: [200/313]\n",
      "Validating Epoch 11: [250/313]\n",
      "Validating Epoch 11: [300/313]\n",
      "Validation: Loss_D: 5.4042 Loss_G: 20.9796 \n",
      "Saving check point\n",
      "Epoch 12/14\n",
      "--------------------\n",
      "Epoch12[0/1563]: Loss_D: 0.4077 (R 0.3964 + F 0.0114) Loss_G: 27.2657 (GAN 4.9150 + R 0.2235) D(x): 0.8747 D(G(z)): 0.0112 / 0.0110\n",
      "Epoch12[500/1563]: Loss_D: 0.0307 (R 0.0147 + F 0.0159) Loss_G: 26.3853 (GAN 5.5328 + R 0.2085) D(x): 0.9854 D(G(z)): 0.0090 / 0.0085\n",
      "Epoch12[1000/1563]: Loss_D: 0.0198 (R 0.0095 + F 0.0103) Loss_G: 26.4928 (GAN 5.6723 + R 0.2082) D(x): 0.9963 D(G(z)): 0.0029 / 0.0029\n",
      "Epoch12[1500/1563]: Loss_D: 0.0195 (R 0.0084 + F 0.0111) Loss_G: 26.9172 (GAN 6.2106 + R 0.2071) D(x): 0.9997 D(G(z)): 0.0132 / 0.0114\n",
      "Validating Epoch 12: [0/313]\n",
      "Validating Epoch 12: [50/313]\n",
      "Validating Epoch 12: [100/313]\n",
      "Validating Epoch 12: [150/313]\n",
      "Validating Epoch 12: [200/313]\n",
      "Validating Epoch 12: [250/313]\n",
      "Validating Epoch 12: [300/313]\n",
      "Validation: Loss_D: 6.6867 Loss_G: 20.7406 \n",
      "Saving check point\n",
      "Epoch 13/14\n",
      "--------------------\n",
      "Epoch13[0/1563]: Loss_D: 0.0097 (R 0.0045 + F 0.0052) Loss_G: 27.9434 (GAN 6.9229 + R 0.2102) D(x): 0.9955 D(G(z)): 0.0050 / 0.0034\n",
      "Epoch13[500/1563]: Loss_D: 0.0259 (R 0.0147 + F 0.0112) Loss_G: 26.8147 (GAN 5.9457 + R 0.2087) D(x): 0.9943 D(G(z)): 0.0058 / 0.0056\n",
      "Epoch13[1000/1563]: Loss_D: 0.0161 (R 0.0064 + F 0.0097) Loss_G: 27.4958 (GAN 6.5462 + R 0.2095) D(x): 0.9993 D(G(z)): 0.0036 / 0.0036\n",
      "Epoch13[1500/1563]: Loss_D: 0.0163 (R 0.0117 + F 0.0047) Loss_G: 26.8845 (GAN 6.2067 + R 0.2068) D(x): 0.9923 D(G(z)): 0.0059 / 0.0055\n",
      "Validating Epoch 13: [0/313]\n",
      "Validating Epoch 13: [50/313]\n",
      "Validating Epoch 13: [100/313]\n",
      "Validating Epoch 13: [150/313]\n",
      "Validating Epoch 13: [200/313]\n",
      "Validating Epoch 13: [250/313]\n",
      "Validating Epoch 13: [300/313]\n",
      "Validation: Loss_D: 0.8529 Loss_G: 21.9370 \n",
      "Saving check point\n",
      "Epoch 14/14\n",
      "--------------------\n",
      "Epoch14[0/1563]: Loss_D: 0.0037 (R 0.0000 + F 0.0036) Loss_G: 27.5365 (GAN 6.0676 + R 0.2147) D(x): 1.0000 D(G(z)): 0.0036 / 0.0036\n",
      "Epoch14[500/1563]: Loss_D: 0.0107 (R 0.0044 + F 0.0062) Loss_G: 26.4097 (GAN 6.1481 + R 0.2026) D(x): 0.9994 D(G(z)): 0.0071 / 0.0067\n",
      "Epoch14[1000/1563]: Loss_D: 0.0140 (R 0.0082 + F 0.0058) Loss_G: 27.0157 (GAN 6.6337 + R 0.2038) D(x): 0.9995 D(G(z)): 0.0041 / 0.0039\n",
      "Epoch14[1500/1563]: Loss_D: 0.0056 (R 0.0018 + F 0.0038) Loss_G: 26.8301 (GAN 6.6865 + R 0.2014) D(x): 0.9995 D(G(z)): 0.0081 / 0.0069\n",
      "Validating Epoch 14: [0/313]\n",
      "Validating Epoch 14: [50/313]\n",
      "Validating Epoch 14: [100/313]\n",
      "Validating Epoch 14: [150/313]\n",
      "Validating Epoch 14: [200/313]\n",
      "Validating Epoch 14: [250/313]\n",
      "Validating Epoch 14: [300/313]\n",
      "Validation: Loss_D: 5.1753 Loss_G: 20.7326 \n",
      "Saving check point\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(start_epoch_D, args_dict['num_epoch']):\n",
    "    print('Epoch {}/{}'.format(epoch, args_dict['num_epoch'] - 1))\n",
    "    print('-' * 20)\n",
    "    if epoch == 0:\n",
    "        val_lerrG, val_errD = validate(val_loader, generator, discriminator, optimizer_generator, optimizer_discriminator, epoch=-1)\n",
    "    # train\n",
    "    train_errG, train_errD = train(train_loader, generator, discriminator, optimizer_generator, optimizer_discriminator, epoch, iteration)\n",
    "    # validate\n",
    "    val_lerrG, val_errD = validate(val_loader, generator, discriminator, optimizer_generator, optimizer_discriminator, epoch)\n",
    "    \n",
    "    plotter.train_update(train_errG, train_errD)\n",
    "    plotter.val_update(val_lerrG, val_errD)\n",
    "    plotter.draw(img_path + 'train_val.png')\n",
    "    \n",
    "    if args_dict['save']:\n",
    "        print('Saving check point')\n",
    "        save_checkpoint({'epoch': epoch + 1,\n",
    "                         'state_dict': generator.state_dict(),\n",
    "                         'optimizer': optimizer_generator.state_dict(),\n",
    "                         },\n",
    "                         filename=model_path+'G_epoch%d.pth.tar' \\\n",
    "                         % epoch)\n",
    "        save_checkpoint({'epoch': epoch + 1,\n",
    "                         'state_dict': discriminator.state_dict(),\n",
    "                         'optimizer': optimizer_discriminator.state_dict(),\n",
    "                         },\n",
    "                         filename=model_path+'D_epoch%d.pth.tar' \\\n",
    "                         % epoch)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0b1e464",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "987bef08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf4604e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e491dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
