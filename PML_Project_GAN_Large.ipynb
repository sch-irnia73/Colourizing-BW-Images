{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571800d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from skimage import color\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "import argparse\n",
    "import shutil\n",
    "import collections\n",
    "import numpy as np\n",
    "import scipy.misc as misc\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a219fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a95e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.relu3 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(256, 256, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(256, 256, 26, stride=2, padding=1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.relu5 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(256, 1, 1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = self.conv1(h)\n",
    "        h = self.bn1(h)\n",
    "        h = self.relu1(h) # 64, 200, 200\n",
    "        \n",
    "        h = self.conv2(h)\n",
    "        h = self.bn2(h)\n",
    "        h = self.relu2(h) # 128, 100, 100\n",
    "        \n",
    "        h = self.conv3(h)\n",
    "        h = self.bn3(h)\n",
    "        h = self.relu3(h) # 256, 50, 50\n",
    "        \n",
    "        h = self.conv4(h)\n",
    "        h = self.bn4(h)\n",
    "        h = self.relu4(h) # 256, 25, 25\n",
    "\n",
    "        h = self.conv5(h)\n",
    "        h = self.bn5(h)\n",
    "        h = self.relu5(h) # 256, 1, 1\n",
    "        \n",
    "        h = self.conv6(h)\n",
    "        h = F.sigmoid(h)\n",
    "\n",
    "        return h\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a2c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 64, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(128, 256, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.relu3 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(256, 256, 3, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.deconv5 = nn.ConvTranspose2d(256, 256, 3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.relu5 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.deconv6 = nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.relu6 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.deconv7 = nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.bn7 = nn.BatchNorm2d(64)\n",
    "        self.relu7 = nn.LeakyReLU(0.1)\n",
    "\n",
    "        self.deconv8 = nn.ConvTranspose2d(64, 3, 3, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.bn8 = nn.BatchNorm2d(3)\n",
    "        self.relu8 = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = self.conv1(h)\n",
    "        h = self.bn1(h)\n",
    "        h = self.relu1(h) # 64, 200, 200\n",
    "        pool1 = h\n",
    "        \n",
    "        h = self.conv2(h)\n",
    "        h = self.bn2(h)\n",
    "        h = self.relu2(h) # 128, 100, 100\n",
    "        pool2 = h\n",
    "        \n",
    "        h = self.conv3(h)\n",
    "        h = self.bn3(h)\n",
    "        h = self.relu3(h) # 256, 50, 50\n",
    "        pool3 = h\n",
    "        \n",
    "        h = self.conv4(h)\n",
    "        h = self.bn4(h)\n",
    "        h = self.relu4(h) # 256, 25, 25\n",
    "\n",
    "        h = self.deconv5(h)\n",
    "        h = self.bn5(h)\n",
    "        h = self.relu5(h) # 256, 50, 50\n",
    "        h += pool3\n",
    "\n",
    "        h = self.deconv6(h)\n",
    "        h = self.bn6(h)\n",
    "        h = self.relu6(h) # 128, 100, 100\n",
    "        h += pool2\n",
    "\n",
    "        h = self.deconv7(h)\n",
    "        h = self.bn7(h)\n",
    "        h = self.relu7(h) # 64, 200, 200\n",
    "        h += pool1\n",
    "        \n",
    "        h = self.deconv8(h)\n",
    "        h = F.tanh(h) # 3, 400, 400\n",
    "\n",
    "        return h\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f1727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35260822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x233e3544890>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b3467b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f52513ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "   'path': '',\n",
    "   'dataset': '',\n",
    "   'large': False,\n",
    "   'batch_size': 32,\n",
    "   'lr': 1e-4,\n",
    "   'weight_decay': 0,\n",
    "   'num_epoch': 15,\n",
    "   'lamb': 100,\n",
    "   'test': '',\n",
    "   'generator': 'model/1127.large/GAN__100L1_bs32_Adam_lr0.0001/G_epoch4.pth.tar',\n",
    "   'discriminator': 'model/1127.large/GAN__100L1_bs32_Adam_lr0.0001/D_epoch4.pth.tar',\n",
    "   'save': True,\n",
    "   'gpu': 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "139fe0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset\n",
    "\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, X_train, y_train):\n",
    "#         self.X_train = X_train\n",
    "#         self.y_train = y_train\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.X_train)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img = self.X_train[idx]\n",
    "#         img = np.array(img)\n",
    "\n",
    "#         img_lab = self.y_train[idx]\n",
    "#         img_lab = np.array(img_lab)\n",
    "\n",
    "#         img = torch.FloatTensor(np.transpose(img, (2,0,1)))\n",
    "#         img_lab = torch.FloatTensor(np.transpose(img_lab, (2,0,1)))\n",
    "\n",
    "#         img = np.reshape(img, img.shape+(1,))\n",
    "#         img_lab = np.reshape(img_lab, img_lab.shape+(1,))\n",
    "\n",
    "\n",
    "#         return img, img_lab\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5de81cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dataset_train = 'data/train_black'\n",
    "root_dataset_test = 'data/test'\n",
    "X_train_images_dir = f'data/train_black'\n",
    "X_test_dir = f'data/test_black'\n",
    "y_train_images_dir = f'data/train_color'\n",
    "y_test_dir = f'data/test_color'\n",
    "X_train, X_test = [], []\n",
    "y_train, y_test = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.CenterCrop(400), transforms.ToTensor()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "   def __init__(self, X_dir, y_dir, transform=None):\n",
    "       self.X_dir = X_dir\n",
    "       self.y_dir = y_dir\n",
    "       self.transform = transform\n",
    "       self.X_filenames = os.listdir(X_dir)\n",
    "       self.y_filenames = os.listdir(y_dir)\n",
    "\n",
    "   def __len__(self):\n",
    "       return len(self.X_filenames)\n",
    "\n",
    "   def __getitem__(self, idx):\n",
    "       X_path = os.path.join(self.X_dir, self.X_filenames[idx])\n",
    "       y_path = os.path.join(self.y_dir, self.y_filenames[idx])\n",
    "       X = Image.open(X_path).convert('L')\n",
    "       y = Image.open(y_path)\n",
    "       if self.transform:\n",
    "           X = self.transform(X)\n",
    "           y = self.transform(y)\n",
    "       return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CustomDataset(X_train_images_dir, y_train_images_dir, transform=transform)\n",
    "\n",
    "train_loader = data.DataLoader(dataset_train, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = CustomDataset(X_test_dir, y_test_dir, transform=transform)\n",
    "\n",
    "val_loader = data.DataLoader(dataset_test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "761a32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in os.listdir(X_train_images_dir):\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         img = cv2.imread(os.path.join(X_train_images_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "#         X_train.append(img)\n",
    "# for filename in os.listdir(X_test_dir):\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         img = cv2.imread(os.path.join(X_test_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "#         X_test.append(img)\n",
    "# for filename in os.listdir(y_train_images_dir):\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         img = cv2.imread(os.path.join(y_train_images_dir, filename))\n",
    "#         y_train.append(img)\n",
    "# for filename in os.listdir(y_test_dir):\n",
    "#     if filename.endswith('.jpg'):\n",
    "#         img = cv2.imread(os.path.join(y_test_dir, filename))\n",
    "#         y_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9be6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #X_train_tensor = torch.from_numpy(np.array(X_train))\n",
    "# #y_train_tensor = torch.from_numpy(np.array(y_train))\n",
    "\n",
    "# X_train = [x.astype('float32') for x in X_train]\n",
    "# y_train = [y.astype('float32') for y in y_train]\n",
    "\n",
    "\n",
    "# dataset = CustomDataset(X_train, y_train)\n",
    "# dataset_val = CustomDataset(X_test, y_test)\n",
    "# #train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "\n",
    "# batch_size = 32\n",
    "# train_loader = data.DataLoader(\n",
    "#     dataset, batch_size=args_dict['batch_size'], shuffle=False\n",
    "# )\n",
    "\n",
    "# batch_size = 32\n",
    "# val_loader = data.DataLoader(\n",
    "#     dataset_val, batch_size=args_dict['batch_size'], shuffle=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee136e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.array(X_train).shape)\n",
    "# print(np.array(y_train).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c2fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57636131",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device=device)\n",
    "discriminator = Discriminator().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502bee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "467f836d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume model G: model/1127.large/GAN__100L1_bs32_Adam_lr0.0001/G_epoch4.pth.tar\n",
      "Resume model D: model/1127.large/GAN__100L1_bs32_Adam_lr0.0001/D_epoch4.pth.tar\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "start_epoch_G = start_epoch_D = 0\n",
    "if args_dict['generator']:\n",
    "    print('Resume model G: %s' % args_dict['generator'])\n",
    "    checkpoint_G = torch.load(args_dict['generator'])\n",
    "    generator.load_state_dict(checkpoint_G['state_dict'])\n",
    "    start_epoch_G = checkpoint_G['epoch']\n",
    "if args_dict['discriminator']:\n",
    "    print('Resume model D: %s' % args_dict['discriminator'])\n",
    "    checkpoint_D = torch.load(args_dict['discriminator'])\n",
    "    discriminator.load_state_dict(checkpoint_D['state_dict'])\n",
    "    start_epoch_D = checkpoint_D['epoch']\n",
    "assert start_epoch_G == start_epoch_D\n",
    "if args_dict['generator'] == '' and args_dict['discriminator'] == '':\n",
    "    print('No Resume')\n",
    "    start_epoch = 0\n",
    "print(start_epoch_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c33284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e7d081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "num_epochs = 50\n",
    "criterion = nn.BCELoss()\n",
    "L1 = nn.L1Loss()\n",
    "\n",
    "optimizer_discriminator = optim.Adam(discriminator.parameters(), \n",
    "            lr=args_dict['lr'], betas=(0.5, 0.999), \n",
    "            eps=1e-8, weight_decay=args_dict['weight_decay'])\n",
    "optimizer_generator = optim.Adam(generator.parameters(), \n",
    "            lr=args_dict['lr'], betas=(0.5, 0.999),\n",
    "            eps=1e-8, weight_decay=args_dict['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12950d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args_dict['generator']:\n",
    "    optimizer_generator.load_state_dict(checkpoint_G['optimizer'])\n",
    "if args_dict['discriminator']:\n",
    "    optimizer_discriminator.load_state_dict(checkpoint_D['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fe101a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scale(object):\n",
    "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "        assert isinstance(size, int) or (isinstance(size, collections.Iterable) and len(size) == 2)\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, img):\n",
    "        print(\"scale\")\n",
    "        if isinstance(self.size, int):\n",
    "            w, h = img.size\n",
    "            if (w <= h and w == self.size) or (h <= w and h == self.size):\n",
    "                return img\n",
    "            if w < h:\n",
    "                ow = self.size\n",
    "                oh = int(self.size * h / w)\n",
    "                return img.resize((ow, oh), self.interpolation)\n",
    "            else:\n",
    "                oh = self.size\n",
    "                ow = int(self.size * w / h)\n",
    "                return img.resize((ow, oh), self.interpolation)\n",
    "        else:\n",
    "            # import ipdb; ipdb.set_trace()\n",
    "            return img.resize(self.size, self.interpolation)\n",
    "        \n",
    "        \n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.history = []\n",
    "        self.dict = {} # save all data values here\n",
    "        self.save_dict = {} # save mean and std here, for summary table\n",
    "\n",
    "    def update(self, val, n=1, history=0):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        if history:\n",
    "            self.history.append(val)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.count\n",
    "\n",
    "class Plotter_GAN(object):\n",
    "    \"\"\"plot loss for G and D\"\"\"\n",
    "    def __init__(self):\n",
    "        self.g_loss = []\n",
    "        self.d_loss = []\n",
    "\n",
    "    def g_update(self, loss):\n",
    "        if type(loss) != float:\n",
    "            loss = float(loss)\n",
    "        self.g_loss.append(loss)\n",
    "\n",
    "    def d_update(self, loss):\n",
    "        if type(loss) != float:\n",
    "            loss = float(loss)\n",
    "        self.d_loss.append(loss)\n",
    "\n",
    "    def draw(self, filename):\n",
    "        name = 'loss'\n",
    "        if len(self.g_loss) == len(self.d_loss):\n",
    "            plt.figure()\n",
    "            plt.plot(self.g_loss, label='G')\n",
    "            plt.plot(self.d_loss, label='D')\n",
    "            plt.legend(loc='upper left')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.title(name)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(filename)\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "\n",
    "class Plotter_GAN_TV(object):\n",
    "    \"\"\"plot loss for G and D with Training and Validation\"\"\"\n",
    "    def __init__(self):\n",
    "        self.g_loss_t = []\n",
    "        self.d_loss_t = []\n",
    "        self.g_loss_v = []\n",
    "        self.d_loss_v = []\n",
    "\n",
    "    def train_update(self, g_loss, d_loss):\n",
    "        if type(g_loss) != float:\n",
    "            g_loss = float(g_loss)\n",
    "        if type(d_loss) != float:\n",
    "            d_loss = float(d_loss)\n",
    "        self.g_loss_t.append(g_loss)\n",
    "        self.d_loss_t.append(d_loss)\n",
    "\n",
    "    def val_update(self, g_loss, d_loss):\n",
    "        if type(g_loss) != float:\n",
    "            g_loss = float(g_loss)\n",
    "        if type(d_loss) != float:\n",
    "            d_loss = float(d_loss)\n",
    "        self.g_loss_v.append(g_loss)\n",
    "        self.d_loss_v.append(d_loss)\n",
    "\n",
    "    def draw(self, filename):\n",
    "        name = 'loss'\n",
    "        if len(self.g_loss_t) == len(self.d_loss_t) and\\\n",
    "           len(self.g_loss_v) == len(self.d_loss_v) and\\\n",
    "           len(self.g_loss_t) == len(self.g_loss_v):\n",
    "            plt.figure()\n",
    "            plt.plot(self.g_loss_t, label='G_train')\n",
    "            plt.plot(self.d_loss_t, label='D_train')\n",
    "            plt.plot(self.g_loss_v, label='G_val')\n",
    "            plt.plot(self.d_loss_v, label='D_val')\n",
    "            plt.legend(loc='upper left')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.title(name)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(filename)\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f69acd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 0\n",
    "print_interval = 500\n",
    "plotter = Plotter_GAN_TV()\n",
    "plotter_basic = Plotter_GAN()\n",
    "date = f'1127.large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "606ef684",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = ''\n",
    "img_path = 'img/%s/GAN_%s%s_%dL1_bs%d_%s_lr%s/' \\\n",
    "           % (date, args_dict['dataset'], size, args_dict['lamb'], args_dict['batch_size'], 'Adam', str(args_dict['lr']))\n",
    "model_path = 'model/%s/GAN_%s%s_%dL1_bs%d_%s_lr%s/' \\\n",
    "           % (date, args_dict['dataset'], size, args_dict['lamb'], args_dict['batch_size'], 'Adam', str(args_dict['lr']))\n",
    "if not os.path.exists(img_path):\n",
    "    os.makedirs(img_path)\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best=0, filename='models/checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'models/model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "328e94c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model_G, model_D, optimizer_G, optimizer_D, epoch, iteration):\n",
    "    errorG = AverageMeter() # will be reset after each epoch\n",
    "    errorD = AverageMeter() # will be reset after each epoch\n",
    "    errorG_basic = AverageMeter() # basic will be reset after each print\n",
    "    errorD_basic = AverageMeter() # basic will be reset after each print\n",
    "    errorD_real = AverageMeter()\n",
    "    errorD_fake = AverageMeter()\n",
    "    errorG_GAN = AverageMeter()\n",
    "    errorG_R = AverageMeter()\n",
    "\n",
    "    model_G.train()\n",
    "    model_D.train()\n",
    "\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data.to(device=device)), Variable(target.to(device=device))\n",
    "\n",
    "        ########################\n",
    "        # update D network\n",
    "        ########################\n",
    "        # train with real\n",
    "        model_D.zero_grad()\n",
    "        output = model_D(target)\n",
    "        label = torch.FloatTensor(target.size(0)).fill_(real_label).to(device=device)\n",
    "        labelv = Variable(label)\n",
    "        errD_real = criterion(torch.squeeze(output), labelv)\n",
    "        errD_real.backward()\n",
    "        D_x = output.data.mean()\n",
    "\n",
    "        # train with fake\n",
    "        fake =  model_G(data)\n",
    "        labelv = Variable(label.fill_(fake_label))\n",
    "        output = model_D(fake.detach())\n",
    "        errD_fake = criterion(torch.squeeze(output), labelv)\n",
    "        errD_fake.backward()\n",
    "        D_G_x1 = output.data.mean()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizer_D.step()\n",
    "\n",
    "        ########################\n",
    "        # update G network\n",
    "        ########################\n",
    "        model_G.zero_grad()\n",
    "        labelv = Variable(label.fill_(real_label))\n",
    "        output = model_D(fake)\n",
    "        errG_GAN = criterion(torch.squeeze(output), labelv)\n",
    "        errG_L1 = L1(fake.view(fake.size(0),-1), target.view(target.size(0),-1))\n",
    "\n",
    "        errG = errG_GAN + args_dict['lamb'] * errG_L1\n",
    "        errG.backward()\n",
    "        D_G_x2 = output.data.mean()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # store error values\n",
    "        errorG.update(errG.item(), target.size(0), history=1)\n",
    "        errorD.update(errD.item(), target.size(0), history=1)\n",
    "        errorG_basic.update(errG.item(), target.size(0), history=1)\n",
    "        errorD_basic.update(errD.item(), target.size(0), history=1)\n",
    "        errorD_real.update(errD_real.item(), target.size(0), history=1)\n",
    "        errorD_fake.update(errD_fake.item(), target.size(0), history=1)\n",
    "\n",
    "        errorD_real.update(errD_real.item(), target.size(0), history=1)\n",
    "        errorD_fake.update(errD_fake.item(), target.size(0), history=1)\n",
    "        errorG_GAN.update(errG_GAN.item(), target.size(0), history=1)\n",
    "        errorG_R.update(errG_L1.item(), target.size(0), history=1)\n",
    "\n",
    "        if iteration % print_interval == 0:\n",
    "            print('Epoch%d[%d/%d]: Loss_D: %.4f (R %0.4f + F %0.4f) Loss_G: %0.4f (GAN %.4f + R %0.4f) D(x): %.4f D(G(z)): %.4f / %.4f' \\\n",
    "                % (epoch, i, len(train_loader),\n",
    "                errorD_basic.avg, errorD_real.avg, errorD_fake.avg,\n",
    "                errorG_basic.avg, errorG_GAN.avg, errorG_R.avg,\n",
    "                D_x, D_G_x1, D_G_x2\n",
    "                ))\n",
    "            # plot image\n",
    "            plotter_basic.g_update(errorG_basic.avg)\n",
    "            plotter_basic.d_update(errorD_basic.avg)\n",
    "            plotter_basic.draw(img_path + 'train_basic.png')\n",
    "            # reset AverageMeter\n",
    "            errorG_basic.reset()\n",
    "            errorD_basic.reset()\n",
    "            errorD_real.reset()\n",
    "            errorD_fake.reset()\n",
    "            errorG_GAN.reset()\n",
    "            errorG_R.reset()\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    return errorG.avg, errorD.avg\n",
    "\n",
    "\n",
    "def validate(val_loader, model_G, model_D, optimizer_G, optimizer_D, epoch):\n",
    "    errorG = AverageMeter()\n",
    "    errorD = AverageMeter()\n",
    "\n",
    "    model_G.eval()\n",
    "    model_D.eval()\n",
    "\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "\n",
    "    i = 0\n",
    "    for i, (data, target) in enumerate(val_loader):\n",
    "        data, target = Variable(data.to(device=device)), Variable(target.to(device=device))\n",
    "        ########################\n",
    "        # D network\n",
    "        ########################\n",
    "        # validate with real\n",
    "        output = model_D(target)\n",
    "        label = torch.FloatTensor(target.size(0)).fill_(real_label).to(device=device)\n",
    "        labelv = Variable(label)\n",
    "        errD_real = criterion(torch.squeeze(output), labelv)\n",
    "\n",
    "        # validate with fake\n",
    "        fake =  model_G(data)\n",
    "        labelv = Variable(label.fill_(fake_label))\n",
    "        output = model_D(fake.detach())\n",
    "        errD_fake = criterion(torch.squeeze(output), labelv)\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "\n",
    "        ########################\n",
    "        # G network\n",
    "        ########################\n",
    "        labelv = Variable(label.fill_(real_label))\n",
    "        output = model_D(fake)\n",
    "        errG_GAN = criterion(torch.squeeze(output), labelv)\n",
    "        errG_L1 = L1(fake.view(fake.size(0),-1), target.view(target.size(0),-1))\n",
    "\n",
    "        errG = errG_GAN + args_dict['lamb'] * errG_L1\n",
    "\n",
    "        errorG.update(errG.item(), target.size(0), history=1)\n",
    "        errorD.update(errD.item(), target.size(0), history=1)\n",
    "\n",
    "        if i == 0:\n",
    "            vis_result(data.data, target.data, fake.data, epoch)\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print('Validating Epoch %d: [%d/%d]' \\\n",
    "                % (epoch, i, len(val_loader)))\n",
    "        \n",
    "\n",
    "    print('Validation: Loss_D: %.4f Loss_G: %.4f '\\\n",
    "        % (errorD.avg, errorG.avg))\n",
    "\n",
    "    return errorG.avg, errorD.avg\n",
    "\n",
    "def vis_result(data, target, output, epoch):\n",
    "    '''visualize images for GAN'''\n",
    "    img_list = []\n",
    "    for i in range(32):\n",
    "        l = torch.unsqueeze(torch.squeeze(data[i]), 0).cpu().numpy()\n",
    "        raw = target[i].cpu().numpy()\n",
    "        pred = output[i].cpu().numpy()\n",
    "\n",
    "        raw_rgb = (np.transpose(raw, (1,2,0)).astype(np.float64) + 1) / 2.\n",
    "        pred_rgb = (np.transpose(pred, (1,2,0)).astype(np.float64) + 1) / 2.\n",
    "\n",
    "        grey = np.transpose(l, (1,2,0))\n",
    "        grey = np.repeat(grey, 3, axis=2).astype(np.float64)\n",
    "        img_list.append(np.concatenate((grey, raw_rgb, pred_rgb), 1))\n",
    "\n",
    "    img_list = [np.concatenate(img_list[4*i:4*(i+1)], axis=1) for i in range(len(img_list) // 4)]\n",
    "    img_list = np.concatenate(img_list, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(36,27))\n",
    "    plt.imshow(img_list)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(img_path + 'epoch%d_val.png' % epoch)\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1149dcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3941e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/14\n",
      "--------------------\n",
      "Epoch5[0/157]: Loss_D: 6.5982 (R 0.1077 + F 6.4904) Loss_G: 27.8142 (GAN 10.0197 + R 0.1779) D(x): 0.9337 D(G(z)): 0.1206 / 0.0871\n",
      "Validating Epoch 5: [0/24]\n",
      "Validation: Loss_D: 12.3291 Loss_G: 20.3519 \n",
      "Saving check point\n",
      "Epoch 6/14\n",
      "--------------------\n",
      "Epoch6[0/157]: Loss_D: 12.8558 (R 0.0389 + F 12.8170) Loss_G: 28.2906 (GAN 12.4967 + R 0.1579) D(x): 0.9672 D(G(z)): 0.1813 / 0.1498\n",
      "Validating Epoch 6: [0/24]\n",
      "Validation: Loss_D: 15.4161 Loss_G: 31.5615 \n",
      "Saving check point\n",
      "Epoch 7/14\n",
      "--------------------\n",
      "Epoch7[0/157]: Loss_D: 28.9765 (R 2.8960 + F 26.0806) Loss_G: 26.4398 (GAN 13.8558 + R 0.1258) D(x): 0.5900 D(G(z)): 0.5266 / 0.4395\n",
      "Validating Epoch 7: [0/24]\n",
      "Validation: Loss_D: 6.6508 Loss_G: 15.4653 \n",
      "Saving check point\n",
      "Epoch 8/14\n",
      "--------------------\n",
      "Epoch8[0/157]: Loss_D: 13.0437 (R 0.3161 + F 12.7277) Loss_G: 17.9587 (GAN 6.3399 + R 0.1162) D(x): 0.8993 D(G(z)): 0.2775 / 0.1946\n",
      "Validating Epoch 8: [0/24]\n",
      "Validation: Loss_D: 14.4958 Loss_G: 14.1302 \n",
      "Saving check point\n",
      "Epoch 9/14\n",
      "--------------------\n",
      "Epoch9[0/157]: Loss_D: 24.4223 (R 1.5584 + F 22.8639) Loss_G: 16.4400 (GAN 4.5916 + R 0.1185) D(x): 0.6799 D(G(z)): 0.4209 / 0.2556\n",
      "Validating Epoch 9: [0/24]\n",
      "Validation: Loss_D: 20.1891 Loss_G: 15.8135 \n",
      "Saving check point\n",
      "Epoch 10/14\n",
      "--------------------\n",
      "Epoch10[0/157]: Loss_D: 14.1555 (R 1.2919 + F 12.8636) Loss_G: 14.8138 (GAN 3.6078 + R 0.1121) D(x): 0.5604 D(G(z)): 0.2382 / 0.1906\n",
      "Validating Epoch 10: [0/24]\n",
      "Validation: Loss_D: 2.7305 Loss_G: 11.3489 \n",
      "Saving check point\n",
      "Epoch 11/14\n",
      "--------------------\n",
      "Epoch11[0/157]: Loss_D: 17.0771 (R 0.5086 + F 16.5685) Loss_G: 14.3443 (GAN 4.6938 + R 0.0965) D(x): 0.8998 D(G(z)): 0.3534 / 0.2590\n",
      "Validating Epoch 11: [0/24]\n",
      "Validation: Loss_D: 1.7476 Loss_G: 10.1655 \n",
      "Saving check point\n",
      "Epoch 12/14\n",
      "--------------------\n",
      "Epoch12[0/157]: Loss_D: 4.5993 (R 0.9311 + F 3.6682) Loss_G: 12.7176 (GAN 2.6936 + R 0.1002) D(x): 0.6008 D(G(z)): 0.2966 / 0.2309\n",
      "Validating Epoch 12: [0/24]\n",
      "Validation: Loss_D: 2.8671 Loss_G: 9.2358 \n",
      "Saving check point\n",
      "Epoch 13/14\n",
      "--------------------\n",
      "Epoch13[0/157]: Loss_D: 0.9662 (R 0.6305 + F 0.3357) Loss_G: 11.6554 (GAN 2.1147 + R 0.0954) D(x): 0.7505 D(G(z)): 0.2377 / 0.1926\n",
      "Validating Epoch 13: [0/24]\n",
      "Validation: Loss_D: 3.7528 Loss_G: 9.6871 \n",
      "Saving check point\n",
      "Epoch 14/14\n",
      "--------------------\n",
      "Epoch14[0/157]: Loss_D: 1.4661 (R 0.9785 + F 0.4876) Loss_G: 11.5712 (GAN 2.6117 + R 0.0896) D(x): 0.7637 D(G(z)): 0.2981 / 0.2170\n",
      "Validating Epoch 14: [0/24]\n",
      "Validation: Loss_D: 5.7071 Loss_G: 9.1400 \n",
      "Saving check point\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x2700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(start_epoch_D, args_dict['num_epoch']):\n",
    "    print('Epoch {}/{}'.format(epoch, args_dict['num_epoch'] - 1))\n",
    "    print('-' * 20)\n",
    "    if epoch == 0:\n",
    "        val_lerrG, val_errD = validate(val_loader, generator, discriminator, optimizer_generator, optimizer_discriminator, epoch=-1)\n",
    "    # train\n",
    "    train_errG, train_errD = train(train_loader, generator, discriminator, optimizer_generator, optimizer_discriminator, epoch, iteration)\n",
    "    # validate\n",
    "    val_lerrG, val_errD = validate(val_loader, generator, discriminator, optimizer_generator, optimizer_discriminator, epoch)\n",
    "    \n",
    "    plotter.train_update(train_errG, train_errD)\n",
    "    plotter.val_update(val_lerrG, val_errD)\n",
    "    plotter.draw(img_path + 'train_val.png')\n",
    "    \n",
    "    if args_dict['save']:\n",
    "        print('Saving check point')\n",
    "        save_checkpoint({'epoch': epoch + 1,\n",
    "                         'state_dict': generator.state_dict(),\n",
    "                         'optimizer': optimizer_generator.state_dict(),\n",
    "                         },\n",
    "                         filename=model_path+'G_epoch%d.pth.tar' \\\n",
    "                         % epoch)\n",
    "        save_checkpoint({'epoch': epoch + 1,\n",
    "                         'state_dict': discriminator.state_dict(),\n",
    "                         'optimizer': optimizer_discriminator.state_dict(),\n",
    "                         },\n",
    "                         filename=model_path+'D_epoch%d.pth.tar' \\\n",
    "                         % epoch)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (data, target) in enumerate(train_loader):\n",
    "    latent_space_samples = Variable(data.to(device=device))\n",
    "    target_v = Variable(target.to(device=device))\n",
    "    if i>32:\n",
    "        break\n",
    "\n",
    "generated_samples = generator(latent_space_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1e464",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_samples = generated_samples.cpu().detach()\n",
    "\n",
    "img_list = []\n",
    "for i in range(32):\n",
    "    l = torch.unsqueeze(torch.squeeze(latent_space_samples[i]), 0).cpu().numpy()\n",
    "    raw = target_v[i].cpu().numpy()\n",
    "    pred = generated_samples[i].cpu().numpy()\n",
    "\n",
    "    raw_rgb = (np.transpose(raw, (1,2,0)).astype(np.float64) + 1) / 2.\n",
    "    pred_rgb = (np.transpose(pred, (1,2,0)).astype(np.float64) + 1) / 2.\n",
    "\n",
    "    grey = np.transpose(l, (1,2,0))\n",
    "    grey = np.repeat(grey, 3, axis=2).astype(np.float64)\n",
    "    img_list.append(np.concatenate((grey, raw_rgb, pred_rgb), 1))\n",
    "\n",
    "img_list = [np.concatenate(img_list[4*i:4*(i+1)], axis=1) for i in range(len(img_list) // 4)]\n",
    "img_list = np.concatenate(img_list, axis=0)\n",
    "\n",
    "plt.figure(figsize=(36,27))\n",
    "plt.imshow(img_list)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig(img_path + 'epoch14_val.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e491dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
